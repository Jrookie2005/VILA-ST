# LAPE åˆå§‹åŒ–åˆ†æå’Œå†œä¸šé¥æ„Ÿå¾®è°ƒç­–ç•¥æŠ¥å‘Š

## 1. LAPE åˆå§‹åŒ–å’Œåå‘ä¼ æ’­æˆåˆ†åˆ†æ

### ğŸ“Š LAPE æ¶‰åŠçš„å¯è®­ç»ƒå‚æ•°

#### 1.1 åµŒå…¥å±‚å‚æ•°
```python
# ç©ºé—´ä½ç½®åµŒå…¥ (é»˜è®¤100ä¸ªtoken)
spatial_height_input_embeddings: torch.nn.Embedding(100, hidden_size)  # ~25.6Må‚æ•° (hidden_size=4096)
spatial_height_output_embeddings: torch.nn.Linear(hidden_size, 100)    # ~409.6Kå‚æ•°

spatial_width_input_embeddings: torch.nn.Embedding(100, hidden_size)   # ~25.6Må‚æ•°  
spatial_width_output_embeddings: torch.nn.Linear(hidden_size, 100)     # ~409.6Kå‚æ•°

# æ—¶é—´ä½ç½®åµŒå…¥ (é»˜è®¤100ä¸ªtoken)
temporal_input_embeddings: torch.nn.Embedding(100, hidden_size)        # ~25.6Må‚æ•°
temporal_output_embeddings: torch.nn.Linear(hidden_size, 100)          # ~409.6Kå‚æ•°
```

**æ€»è®¡**: ~77.1M é¢å¤–å‚æ•° (çº¦å 7Bæ¨¡å‹çš„1.1%)

#### 1.2 é‡å‚æ•°åŒ–çŸ©é˜µ (å›ºå®šï¼Œä¸å‚ä¸è®­ç»ƒ)
```python
# é‚»è¿‘Tokenä¼ æ’­(NTP)çŸ©é˜µ
spatial_width_reparam_mat: [100, 100]   # å›ºå®šæƒé‡ï¼Œ2^(-|i-j|)
spatial_height_reparam_mat: [100, 100]  # å›ºå®šæƒé‡  
temporal_reparam_mat: [100, 100]        # å›ºå®šæƒé‡
```

### ğŸ”„ åå‘ä¼ æ’­æ›´æ–°æœºåˆ¶

#### 1.3 æ¢¯åº¦æµè·¯å¾„
```
å›¾åƒç‰¹å¾ â†’ Vision Encoder â†’ MM Projector â†’ LAPEæ³¨å…¥ â†’ LLM
    â†‘                           â†‘              â†‘
    |                           |              |
è§†è§‰å¡”å‚æ•°                   æŠ•å½±å™¨å‚æ•°        LAPEåµŒå…¥å‚æ•°
(å¯é€‰æ›´æ–°)                  (é€šå¸¸æ›´æ–°)        (æ–°å¢ï¼Œéœ€warmup)
```

#### 1.4 LAPEå‚æ•°æ¢¯åº¦æ¥æº
1. **ç›´æ¥æ¢¯åº¦**: ä»position tokenåœ¨æ–‡æœ¬ä¸­çš„ä½¿ç”¨
2. **é—´æ¥æ¢¯åº¦**: ä»LAPEæ³¨å…¥åˆ°å›¾åƒç‰¹å¾çš„å½±å“
3. **NTPæ¢¯åº¦**: é€šè¿‡reparamæœºåˆ¶çš„é‚»è¿‘ä¼ æ’­

## 2. å½“å‰åˆå§‹åŒ–é—®é¢˜åˆ†æ

### âš ï¸ é—®é¢˜è¯†åˆ«

#### 2.1 éšæœºåˆå§‹åŒ–é—®é¢˜
```python
# å½“å‰å®ç°ï¼šéšæœºåˆå§‹åŒ–æ‰€æœ‰LAPEåµŒå…¥
self.spatial_height_input_embeddings = torch.nn.Embedding(100, hidden_size)
# é—®é¢˜ï¼šæ²¡æœ‰åˆç†çš„åˆå§‹åŒ–ç­–ç•¥ï¼Œå¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š
```

#### 2.2 ç¼ºå°‘gradual warmup
- LAPEå‚æ•°ä»é›¶å¼€å§‹å­¦ä¹ ï¼Œå¯èƒ½ä¸é¢„è®­ç»ƒç‰¹å¾ä¸åŒ¹é…
- æ²¡æœ‰é€æ­¥å¼•å…¥ä½ç½®ä¿¡æ¯çš„æœºåˆ¶

#### 2.3 å­¦ä¹ ç‡è®¾ç½®
- LAPEå‚æ•°ä½¿ç”¨ä¸ä¸»æ¨¡å‹ç›¸åŒçš„å­¦ä¹ ç‡
- æ–°å¢å‚æ•°å¯èƒ½éœ€è¦ä¸åŒçš„å­¦ä¹ ç‡ç­–ç•¥

## 3. å†œä¸šé¥æ„Ÿé¢†åŸŸä¼˜åŒ–ç­–ç•¥

### ğŸŒ¾ å†œä¸šé¥æ„Ÿç‰¹æ®Šæ€§è€ƒè™‘

#### 3.1 ç©ºé—´ç‰¹å¾é‡è¦æ€§
- **é«˜åˆ†è¾¨ç‡éœ€æ±‚**: å†œä½œç‰©è¾¹ç•Œã€ç—…è™«å®³åŒºåŸŸå®šä½
- **å¤šå°ºåº¦åˆ†æ**: ä»ç”°å—åˆ°ä½œç‰©è¡Œçº§åˆ«çš„ç©ºé—´ç†è§£
- **å­£èŠ‚æ€§å˜åŒ–**: æ—¶é—´ç»´åº¦çš„ä½œç‰©ç”Ÿé•¿å‘¨æœŸå»ºæ¨¡

#### 3.2 LAPEåœ¨å†œä¸šé¥æ„Ÿä¸­çš„ä»·å€¼
- **ç²¾ç¡®å®šä½**: ç©ºé—´ä½ç½®ç¼–ç å¸®åŠ©æ¨¡å‹ç†è§£ç”°å—è¾¹ç•Œ
- **æ—¶åºå»ºæ¨¡**: æ—¶é—´ä½ç½®ç¼–ç æ•æ‰ä½œç‰©ç”Ÿé•¿é˜¶æ®µ
- **å¤šæ¨¡æ€èåˆ**: ç»“åˆé¥æ„Ÿå›¾åƒå’Œåœ°ç†ä¿¡æ¯

### ğŸ¯ Stage2 Warmupç­–ç•¥å»ºè®®

#### 3.3 æ¨èçš„ä¸‰é˜¶æ®µè®­ç»ƒç­–ç•¥

**Stage 1: Vision-Language Alignment (æ— LAPE)**
- ç›®æ ‡: å»ºç«‹åŸºç¡€çš„è§†è§‰-è¯­è¨€å¯¹é½
- LAPEçŠ¶æ€: ç¦ç”¨
- æ•°æ®: é€šç”¨å›¾åƒ-æ–‡æœ¬å¯¹

**Stage 2: LAPE Warmup (æ¸è¿›å¼LAPE)**  
- ç›®æ ‡: é€æ­¥å¼•å…¥ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
- LAPEçŠ¶æ€: å¯ç”¨ï¼Œä½†ä½¿ç”¨ç‰¹æ®Šåˆå§‹åŒ–å’Œå­¦ä¹ ç‡
- æ•°æ®: é¥æ„Ÿå›¾åƒ + ä½ç½®ç›¸å…³æè¿°

**Stage 3: Domain-Specific Fine-tuning**
- ç›®æ ‡: å†œä¸šé¢†åŸŸä¸“é—¨åŒ–  
- LAPEçŠ¶æ€: å…¨é¢å¯ç”¨
- æ•°æ®: å†œä¸šé¥æ„Ÿä¸“ç”¨æ•°æ®é›†

## 4. å®æ–½æ–¹æ¡ˆ

### ğŸ’¡ æ”¹è¿›çš„LAPEåˆå§‹åŒ–ç­–ç•¥

#### 4.1 æ™ºèƒ½åˆå§‹åŒ–
```python
def smart_init_lape_embeddings(self):
    """åŸºäºå·²æœ‰embeddingsçš„æ™ºèƒ½åˆå§‹åŒ–"""
    # ä½¿ç”¨LLM embeddingçš„ç»Ÿè®¡ä¿¡æ¯
    token_embed_mean = self.llm.get_input_embeddings().weight.mean()
    token_embed_std = self.llm.get_input_embeddings().weight.std()
    
    # ç”¨æ›´å°çš„æ–¹å·®åˆå§‹åŒ–LAPE
    init_std = token_embed_std * 0.1  # 10%çš„æ ‡å‡†å·®
    
    with torch.no_grad():
        for embed in [self.spatial_height_input_embeddings, 
                     self.spatial_width_input_embeddings,
                     self.temporal_input_embeddings]:
            nn.init.normal_(embed.weight, mean=token_embed_mean, std=init_std)
```

#### 4.2 æ¸è¿›å¼warmup
```python
def get_lape_learning_rate(self, base_lr, current_step, warmup_steps):
    """LAPEä¸“ç”¨å­¦ä¹ ç‡è°ƒåº¦"""
    if current_step < warmup_steps:
        # WarmupæœŸé—´ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
        return base_lr * 0.1 * (current_step / warmup_steps)
    else:
        # æ­£å¸¸è®­ç»ƒæœŸé—´
        return base_lr * 0.5  # LAPEä½¿ç”¨ä¸€åŠçš„å­¦ä¹ ç‡
```

### ğŸ”§ é…ç½®å»ºè®®

#### 4.3 å†œä¸šé¥æ„Ÿä¼˜åŒ–å‚æ•°
```bash
# Stage 2: LAPE Warmup é…ç½®
--enable_lape True
--num_spatial_tokens 150    # æ›´å¤šç©ºé—´tokenç”¨äºé«˜åˆ†è¾¨ç‡
--num_temporal_tokens 50    # è¾ƒå°‘æ—¶é—´tokenï¼ˆå†œä¸šå­£èŠ‚æ€§ï¼‰
--lape_warmup_steps 1000    # LAPEé¢„çƒ­æ­¥æ•°
--lape_lr_multiplier 0.5    # LAPEå­¦ä¹ ç‡å€æ•°
--spatial_pos_weight 2.0    # ç©ºé—´ä½ç½®æƒé‡ï¼ˆå†œä¸šé‡è¦ï¼‰
--temporal_pos_weight 1.0   # æ—¶é—´ä½ç½®æƒé‡
```

#### 4.4 æ•°æ®ç­–ç•¥
```yaml
stage2_data_mixture:
  # é€šç”¨é¥æ„Ÿæ•°æ® (å»ºç«‹ç©ºé—´ç†è§£)
  - remote_sensing_general: 0.4
  # å†œä¸šç›¸å…³æ•°æ® (é¢†åŸŸé€‚åº”)  
  - agricultural_images: 0.4
  # ä½ç½®æ•æ„Ÿä»»åŠ¡ (å¼ºåŒ–LAPE)
  - spatial_reasoning_tasks: 0.2
```

## 5. å®æ–½å»ºè®®

### âœ… ç«‹å³è¡ŒåŠ¨é¡¹

1. **åˆ›å»ºStage 2 LAPE Warmupè„šæœ¬**
2. **å®ç°æ™ºèƒ½LAPEåˆå§‹åŒ–**  
3. **è®¾è®¡å†œä¸šé¥æ„Ÿè¯„ä¼°æŒ‡æ ‡**
4. **å‡†å¤‡åˆ†é˜¶æ®µè®­ç»ƒæ•°æ®**

### ğŸ“ˆ é¢„æœŸæ•ˆæœ

- **æ›´ç¨³å®šçš„è®­ç»ƒ**: æ¸è¿›å¼LAPEå¼•å…¥å‡å°‘è®­ç»ƒéœ‡è¡
- **æ›´å¥½çš„ç©ºé—´ç†è§£**: é’ˆå¯¹é¥æ„Ÿæ•°æ®çš„ä½ç½®ç¼–ç ä¼˜åŒ–  
- **é¢†åŸŸé€‚åº”æ€§**: ä¸“é—¨çš„å†œä¸šé¥æ„Ÿå¾®è°ƒç­–ç•¥
- **æ€§èƒ½æå‡**: åœ¨å†œä¸šä»»åŠ¡ä¸Šé¢„æœŸ5-10%çš„æ€§èƒ½æå‡

### âš¡ å…³é”®æˆåŠŸå› ç´ 

1. **åˆç†çš„warmupç­–ç•¥**: é¿å…LAPEå‚æ•°è®­ç»ƒåˆæœŸçš„ä¸ç¨³å®š
2. **é¢†åŸŸç‰¹å®šæ•°æ®**: é«˜è´¨é‡çš„å†œä¸šé¥æ„Ÿè®­ç»ƒæ•°æ®
3. **è¯„ä¼°ä½“ç³»**: å»ºç«‹å†œä¸šä»»åŠ¡çš„ä¸“é—¨è¯„ä¼°æŒ‡æ ‡
4. **è¿­ä»£ä¼˜åŒ–**: åŸºäºå®éªŒç»“æœè°ƒæ•´å‚æ•°é…ç½®

---

**ç»“è®º**: Stage 2çš„LAPE warmupå¯¹å†œä¸šé¥æ„Ÿå¾®è°ƒæ˜¯**å¿…è¦ä¸”æœ‰ç›Šçš„**ï¼Œå»ºè®®å®æ–½æ¸è¿›å¼è®­ç»ƒç­–ç•¥ã€‚